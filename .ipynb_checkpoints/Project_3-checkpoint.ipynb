{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/williammdavis/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "from string import digits\n",
    "import numpy as np\n",
    "import os\n",
    "import nltk\n",
    "import string\n",
    "from nltk.corpus import stopwords  \n",
    "from nltk.tokenize import word_tokenize  \n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from collections import defaultdict\n",
    "from nltk.probability import FreqDist, DictionaryProbDist, ELEProbDist, sum_logs\n",
    "from nltk.classify.api import ClassifierI\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Index_No</th>\n",
       "      <th>Description_and_Skill</th>\n",
       "      <th>Job_Title</th>\n",
       "      <th>Job_Type</th>\n",
       "      <th>Queried_Salary</th>\n",
       "      <th>&lt;80000</th>\n",
       "      <th>80000-99999</th>\n",
       "      <th>100000-119999</th>\n",
       "      <th>120000-139999</th>\n",
       "      <th>140000-159999</th>\n",
       "      <th>&gt;160000</th>\n",
       "      <th>Salary_Index</th>\n",
       "      <th>Sal_Ind_Cat4-5-6</th>\n",
       "      <th>Skill</th>\n",
       "      <th>No_of_Skills</th>\n",
       "      <th>Location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[POSITION SUMMARY, The Business Analyst role i...</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>&lt;80000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>['SAP', 'SQL']</td>\n",
       "      <td>2.0</td>\n",
       "      <td>MO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>[What do we need?, You to have an amazing pers...</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>&lt;80000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>['Machine Learning', 'R', 'SAS', 'SQL', 'Python']</td>\n",
       "      <td>5.0</td>\n",
       "      <td>TX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>[Validate, analyze, and conduct statistical an...</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>&lt;80000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>['Data Mining', 'Data Management', 'R', 'SAS',...</td>\n",
       "      <td>9.0</td>\n",
       "      <td>OR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>[Full time, Washington, DC metro area, Startin...</td>\n",
       "      <td>Graduate Studies Program - Data Scientist</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>&lt;80000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>['Certified Internal Auditor']</td>\n",
       "      <td>1.0</td>\n",
       "      <td>DC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>[Assist in consultations with business partner...</td>\n",
       "      <td>Data Scientist I</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>&lt;80000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>['Statistical Software', 'Time Management', 'R...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>TX</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Index_No                              Description_and_Skill  \\\n",
       "0         0  [POSITION SUMMARY, The Business Analyst role i...   \n",
       "1         1  [What do we need?, You to have an amazing pers...   \n",
       "2         2  [Validate, analyze, and conduct statistical an...   \n",
       "3         3  [Full time, Washington, DC metro area, Startin...   \n",
       "4         4  [Assist in consultations with business partner...   \n",
       "\n",
       "                                   Job_Title        Job_Type Queried_Salary  \\\n",
       "0                             Data Scientist  Data Scientist         <80000   \n",
       "1                             Data Scientist  Data Scientist         <80000   \n",
       "2                             Data Scientist  Data Scientist         <80000   \n",
       "3  Graduate Studies Program - Data Scientist  Data Scientist         <80000   \n",
       "4                           Data Scientist I  Data Scientist         <80000   \n",
       "\n",
       "   <80000  80000-99999  100000-119999  120000-139999  140000-159999  >160000  \\\n",
       "0       1            0              0              0              0        0   \n",
       "1       1            0              0              0              0        0   \n",
       "2       1            0              0              0              0        0   \n",
       "3       1            0              0              0              0        0   \n",
       "4       1            0              0              0              0        0   \n",
       "\n",
       "   Salary_Index  Sal_Ind_Cat4-5-6  \\\n",
       "0             1                 0   \n",
       "1             1                 0   \n",
       "2             1                 0   \n",
       "3             1                 0   \n",
       "4             1                 0   \n",
       "\n",
       "                                               Skill  No_of_Skills Location  \n",
       "0                                     ['SAP', 'SQL']           2.0       MO  \n",
       "1  ['Machine Learning', 'R', 'SAS', 'SQL', 'Python']           5.0       TX  \n",
       "2  ['Data Mining', 'Data Management', 'R', 'SAS',...           9.0       OR  \n",
       "3                     ['Certified Internal Auditor']           1.0       DC  \n",
       "4  ['Statistical Software', 'Time Management', 'R...           7.0       TX  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv = \"./df.csv\"\n",
    "df = pd.read_csv(csv, encoding = 'unicode_escape')\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "572\n"
     ]
    }
   ],
   "source": [
    "df_sample = df.sample(frac =.1) \n",
    "df_sample.head()\n",
    "print(len(df_sample))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job_Type</th>\n",
       "      <th>Description_and_Skill</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3935</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>[This role will be a part of the Data Reposito...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4417</th>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>['Java', 'Spring', 'Predictive Analytics', 'S3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>622</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>[The Associate Data Scientist performs data an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2261</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>[US citizenship plus current TS/ SCI + FS Poly...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>[Req ID: 40161, Lubrizol, a Berkshire Hathaway...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Job_Type                              Description_and_Skill\n",
       "3935    Data Analyst  [This role will be a part of the Data Reposito...\n",
       "4417   Data Engineer  ['Java', 'Spring', 'Predictive Analytics', 'S3...\n",
       "622   Data Scientist  [The Associate Data Scientist performs data an...\n",
       "2261  Data Scientist  [US citizenship plus current TS/ SCI + FS Poly...\n",
       "183   Data Scientist  [Req ID: 40161, Lubrizol, a Berkshire Hathaway..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3 = df_sample[['Job_Type', 'Description_and_Skill']]\n",
    "df3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df3.to_csv('df3.csv')\n",
    "# df.describe()\n",
    "# df.dtypes\n",
    "# len(df3['Description'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/williammdavis/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "570"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3.dropna(inplace=True)\n",
    "len(df3['Description_and_Skill'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_text(text):\n",
    "    nopunc = [char for char in text if char not in string.punctuation]\n",
    "    nopunc = ''.join(nopunc)\n",
    "    clean_words = [word for word in nopunc.split() if word.lower() not in stopwords.words('english')]\n",
    "    return clean_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [POSITION, SUMMARY, Business, Analyst, role, p...\n",
       "1    [need, amazing, personality, communication, st...\n",
       "2    [Validate, analyze, conduct, statistical, anal...\n",
       "3    [Full, time, Washington, DC, metro, area, Star...\n",
       "4    [Assist, consultations, business, partners, in...\n",
       "Name: Description_and_Skill, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Description_and_Skill'].head().apply(process_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert collection of text to a matrix of tokens\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "count_v  = CountVectorizer(analyzer=process_text)\n",
    "message_bow = count_v.fit_transform(df3['Description_and_Skill'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split the data into 80% training and 20% testing\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(message_bow, df3['Job_Type'],test_size=0.20, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# message_bow.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create and train the naive bayes classifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "classifier =  MultinomialNB().fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Data Analyst' 'Data Scientist' 'Data Engineer' 'Data Scientist'\n",
      " 'Data Scientist' 'Data Scientist' 'Data Analyst' 'Data Engineer'\n",
      " 'Data Engineer' 'Data Engineer' 'Data Engineer' 'Data Engineer'\n",
      " 'Data Analyst' 'Data Scientist' 'Data Scientist' 'Data Analyst'\n",
      " 'Data Scientist' 'Data Analyst' 'Data Scientist' 'Data Engineer'\n",
      " 'Data Analyst' 'Data Analyst' 'Data Scientist' 'Data Analyst'\n",
      " 'Data Analyst' 'Data Analyst' 'Data Scientist' 'Data Analyst'\n",
      " 'Data Analyst' 'Data Scientist' 'Data Scientist' 'Data Engineer'\n",
      " 'Data Engineer' 'Data Analyst' 'Data Analyst' 'Data Analyst'\n",
      " 'Data Scientist' 'Data Scientist' 'Data Engineer' 'Data Scientist'\n",
      " 'Data Scientist' 'Data Analyst' 'Data Scientist' 'Data Analyst'\n",
      " 'Data Scientist' 'Data Scientist' 'Data Analyst' 'Data Engineer'\n",
      " 'Data Engineer' 'Data Scientist' 'Data Analyst' 'Data Scientist'\n",
      " 'Data Scientist' 'Data Scientist' 'Data Engineer' 'Data Analyst'\n",
      " 'Data Scientist' 'Data Scientist' 'Data Analyst' 'Data Engineer'\n",
      " 'Data Engineer' 'Data Engineer' 'Data Scientist' 'Data Analyst'\n",
      " 'Data Scientist' 'Data Engineer' 'Data Scientist' 'Data Scientist'\n",
      " 'Data Analyst' 'Data Analyst' 'Data Analyst' 'Data Scientist'\n",
      " 'Data Analyst' 'Data Scientist' 'Data Engineer' 'Data Analyst'\n",
      " 'Data Scientist' 'Data Scientist' 'Data Scientist' 'Data Engineer'\n",
      " 'Data Engineer' 'Data Engineer' 'Data Analyst' 'Data Analyst'\n",
      " 'Data Analyst' 'Data Analyst' 'Data Analyst' 'Data Scientist'\n",
      " 'Data Scientist' 'Data Engineer' 'Data Scientist' 'Data Scientist'\n",
      " 'Data Analyst' 'Data Scientist' 'Data Scientist' 'Data Analyst'\n",
      " 'Data Analyst' 'Data Analyst' 'Data Scientist' 'Data Scientist'\n",
      " 'Data Analyst' 'Data Engineer' 'Data Engineer' 'Data Engineer'\n",
      " 'Data Analyst' 'Data Scientist' 'Data Scientist' 'Data Scientist'\n",
      " 'Data Engineer' 'Data Scientist' 'Data Engineer' 'Data Engineer'\n",
      " 'Data Scientist' 'Data Engineer' 'Data Engineer' 'Data Scientist'\n",
      " 'Data Scientist' 'Data Scientist' 'Data Analyst' 'Data Scientist'\n",
      " 'Data Scientist' 'Data Scientist' 'Data Engineer' 'Data Engineer'\n",
      " 'Data Scientist' 'Data Analyst' 'Data Scientist' 'Data Scientist'\n",
      " 'Data Scientist' 'Data Analyst' 'Data Scientist' 'Data Analyst'\n",
      " 'Data Analyst' 'Data Scientist' 'Data Engineer' 'Data Scientist'\n",
      " 'Data Engineer' 'Data Scientist' 'Data Scientist' 'Data Analyst'\n",
      " 'Data Analyst' 'Data Scientist' 'Data Engineer' 'Data Scientist'\n",
      " 'Data Analyst' 'Data Scientist' 'Data Engineer' 'Data Analyst'\n",
      " 'Data Analyst' 'Data Engineer' 'Data Scientist' 'Data Engineer'\n",
      " 'Data Analyst' 'Data Scientist' 'Data Scientist' 'Data Engineer'\n",
      " 'Data Scientist' 'Data Scientist' 'Data Engineer' 'Data Scientist'\n",
      " 'Data Scientist' 'Data Analyst' 'Data Analyst' 'Data Analyst'\n",
      " 'Data Scientist' 'Data Analyst' 'Data Scientist' 'Data Analyst'\n",
      " 'Data Analyst' 'Data Engineer' 'Data Engineer' 'Data Scientist'\n",
      " 'Data Engineer' 'Data Scientist' 'Data Engineer' 'Data Scientist'\n",
      " 'Data Scientist' 'Data Engineer' 'Data Scientist' 'Data Scientist'\n",
      " 'Data Engineer' 'Data Engineer' 'Data Scientist' 'Data Analyst'\n",
      " 'Data Scientist' 'Data Analyst' 'Data Scientist' 'Data Engineer'\n",
      " 'Data Engineer' 'Data Scientist' 'Data Scientist' 'Data Scientist'\n",
      " 'Data Analyst' 'Data Analyst' 'Data Engineer' 'Data Engineer'\n",
      " 'Data Scientist' 'Data Analyst' 'Data Engineer' 'Data Engineer'\n",
      " 'Data Analyst' 'Data Engineer' 'Data Scientist' 'Data Scientist'\n",
      " 'Data Scientist' 'Data Engineer' 'Data Engineer' 'Data Scientist'\n",
      " 'Data Scientist' 'Data Engineer' 'Data Analyst' 'Data Analyst'\n",
      " 'Data Engineer' 'Data Scientist' 'Data Engineer' 'Data Analyst'\n",
      " 'Data Engineer' 'Data Scientist' 'Data Engineer' 'Data Analyst'\n",
      " 'Data Engineer' 'Data Engineer' 'Data Scientist' 'Data Scientist'\n",
      " 'Data Scientist' 'Data Scientist' 'Data Engineer' 'Data Scientist'\n",
      " 'Data Scientist' 'Data Scientist' 'Data Scientist' 'Data Scientist'\n",
      " 'Data Analyst' 'Data Engineer' 'Data Analyst' 'Data Analyst'\n",
      " 'Data Engineer' 'Data Engineer' 'Data Scientist' 'Data Scientist'\n",
      " 'Data Engineer' 'Data Engineer' 'Data Scientist' 'Data Analyst'\n",
      " 'Data Analyst' 'Data Engineer' 'Data Scientist' 'Data Scientist'\n",
      " 'Data Scientist' 'Data Scientist' 'Data Engineer' 'Data Analyst'\n",
      " 'Data Scientist' 'Data Scientist' 'Data Scientist' 'Data Analyst'\n",
      " 'Data Scientist' 'Data Scientist' 'Data Scientist' 'Data Engineer'\n",
      " 'Data Scientist' 'Data Analyst' 'Data Engineer' 'Data Analyst'\n",
      " 'Data Engineer' 'Data Analyst' 'Data Engineer' 'Data Scientist'\n",
      " 'Data Engineer' 'Data Engineer' 'Data Analyst' 'Data Scientist'\n",
      " 'Data Analyst' 'Data Engineer' 'Data Analyst' 'Data Engineer'\n",
      " 'Data Scientist' 'Data Scientist' 'Data Analyst' 'Data Analyst'\n",
      " 'Data Analyst' 'Data Analyst' 'Data Scientist' 'Data Engineer'\n",
      " 'Data Scientist' 'Data Scientist' 'Data Engineer' 'Data Scientist'\n",
      " 'Data Engineer' 'Data Scientist' 'Data Scientist' 'Data Analyst'\n",
      " 'Data Scientist' 'Data Scientist' 'Data Scientist' 'Data Scientist'\n",
      " 'Data Analyst' 'Data Analyst' 'Data Scientist' 'Data Analyst'\n",
      " 'Data Analyst' 'Data Analyst' 'Data Scientist' 'Data Scientist'\n",
      " 'Data Analyst' 'Data Scientist' 'Data Scientist' 'Data Scientist'\n",
      " 'Data Scientist' 'Data Scientist' 'Data Analyst' 'Data Scientist'\n",
      " 'Data Engineer' 'Data Analyst' 'Data Engineer' 'Data Analyst'\n",
      " 'Data Analyst' 'Data Scientist' 'Data Engineer' 'Data Engineer'\n",
      " 'Data Engineer' 'Data Scientist' 'Data Analyst' 'Data Scientist'\n",
      " 'Data Scientist' 'Data Analyst' 'Data Scientist' 'Data Engineer'\n",
      " 'Data Scientist' 'Data Analyst' 'Data Scientist' 'Data Engineer'\n",
      " 'Data Engineer' 'Data Analyst' 'Data Scientist' 'Data Engineer'\n",
      " 'Data Engineer' 'Data Scientist' 'Data Analyst' 'Data Scientist'\n",
      " 'Data Scientist' 'Data Scientist' 'Data Scientist' 'Data Analyst'\n",
      " 'Data Scientist' 'Data Scientist' 'Data Analyst' 'Data Scientist'\n",
      " 'Data Scientist' 'Data Scientist' 'Data Analyst' 'Data Engineer'\n",
      " 'Data Scientist' 'Data Analyst' 'Data Scientist' 'Data Scientist'\n",
      " 'Data Analyst' 'Data Analyst' 'Data Analyst' 'Data Scientist'\n",
      " 'Data Analyst' 'Data Engineer' 'Data Analyst' 'Data Engineer'\n",
      " 'Data Engineer' 'Data Analyst' 'Data Scientist' 'Data Analyst'\n",
      " 'Data Scientist' 'Data Scientist' 'Data Engineer' 'Data Scientist'\n",
      " 'Data Scientist' 'Data Analyst' 'Data Analyst' 'Data Engineer'\n",
      " 'Data Analyst' 'Data Scientist' 'Data Scientist' 'Data Engineer'\n",
      " 'Data Scientist' 'Data Scientist' 'Data Engineer' 'Data Scientist'\n",
      " 'Data Analyst' 'Data Scientist' 'Data Scientist' 'Data Engineer'\n",
      " 'Data Analyst' 'Data Scientist' 'Data Engineer' 'Data Analyst'\n",
      " 'Data Analyst' 'Data Scientist' 'Data Analyst' 'Data Engineer'\n",
      " 'Data Analyst' 'Data Scientist' 'Data Analyst' 'Data Scientist'\n",
      " 'Data Scientist' 'Data Analyst' 'Data Analyst' 'Data Engineer'\n",
      " 'Data Engineer' 'Data Analyst' 'Data Analyst' 'Data Scientist'\n",
      " 'Data Analyst' 'Data Scientist' 'Data Analyst' 'Data Analyst'\n",
      " 'Data Analyst' 'Data Engineer' 'Data Analyst' 'Data Scientist'\n",
      " 'Data Scientist' 'Data Analyst' 'Data Analyst' 'Data Engineer'\n",
      " 'Data Engineer' 'Data Engineer' 'Data Scientist' 'Data Scientist'\n",
      " 'Data Scientist' 'Data Analyst' 'Data Engineer' 'Data Engineer'\n",
      " 'Data Analyst' 'Data Scientist' 'Data Analyst' 'Data Engineer'\n",
      " 'Data Engineer' 'Data Analyst' 'Data Scientist' 'Data Scientist'\n",
      " 'Data Analyst' 'Data Scientist' 'Data Analyst' 'Data Scientist'\n",
      " 'Data Scientist' 'Data Analyst' 'Data Analyst' 'Data Analyst'\n",
      " 'Data Scientist' 'Data Scientist' 'Data Engineer' 'Data Scientist'\n",
      " 'Data Engineer' 'Data Engineer' 'Data Scientist' 'Data Analyst'\n",
      " 'Data Engineer' 'Data Analyst' 'Data Scientist' 'Data Scientist']\n",
      "['Data Analyst' 'Data Scientist' 'Data Engineer' 'Data Scientist'\n",
      " 'Data Scientist' 'Data Scientist' 'Data Analyst' 'Data Engineer'\n",
      " 'Data Engineer' 'Data Engineer' 'Data Engineer' 'Data Engineer'\n",
      " 'Data Analyst' 'Data Scientist' 'Data Scientist' 'Data Analyst'\n",
      " 'Data Scientist' 'Data Analyst' 'Data Scientist' 'Data Engineer'\n",
      " 'Data Analyst' 'Data Scientist' 'Data Scientist' 'Data Analyst'\n",
      " 'Data Analyst' 'Data Analyst' 'Data Scientist' 'Data Scientist'\n",
      " 'Data Analyst' 'Data Scientist' 'Data Scientist' 'Data Engineer'\n",
      " 'Data Engineer' 'Data Analyst' 'Data Analyst' 'Data Analyst'\n",
      " 'Data Scientist' 'Data Scientist' 'Data Engineer' 'Data Scientist'\n",
      " 'Data Scientist' 'Data Analyst' 'Data Scientist' 'Data Analyst'\n",
      " 'Data Scientist' 'Data Scientist' 'Data Analyst' 'Data Engineer'\n",
      " 'Data Engineer' 'Data Scientist' 'Data Analyst' 'Data Scientist'\n",
      " 'Data Scientist' 'Data Scientist' 'Data Engineer' 'Data Analyst'\n",
      " 'Data Scientist' 'Data Scientist' 'Data Analyst' 'Data Engineer'\n",
      " 'Data Engineer' 'Data Engineer' 'Data Scientist' 'Data Analyst'\n",
      " 'Data Scientist' 'Data Engineer' 'Data Scientist' 'Data Scientist'\n",
      " 'Data Analyst' 'Data Analyst' 'Data Analyst' 'Data Scientist'\n",
      " 'Data Analyst' 'Data Scientist' 'Data Scientist' 'Data Analyst'\n",
      " 'Data Scientist' 'Data Analyst' 'Data Scientist' 'Data Engineer'\n",
      " 'Data Engineer' 'Data Engineer' 'Data Analyst' 'Data Analyst'\n",
      " 'Data Scientist' 'Data Analyst' 'Data Analyst' 'Data Scientist'\n",
      " 'Data Scientist' 'Data Engineer' 'Data Scientist' 'Data Scientist'\n",
      " 'Data Analyst' 'Data Scientist' 'Data Scientist' 'Data Analyst'\n",
      " 'Data Analyst' 'Data Analyst' 'Data Scientist' 'Data Scientist'\n",
      " 'Data Analyst' 'Data Engineer' 'Data Engineer' 'Data Engineer'\n",
      " 'Data Analyst' 'Data Scientist' 'Data Scientist' 'Data Scientist'\n",
      " 'Data Engineer' 'Data Scientist' 'Data Engineer' 'Data Engineer'\n",
      " 'Data Scientist' 'Data Engineer' 'Data Engineer' 'Data Scientist'\n",
      " 'Data Scientist' 'Data Scientist' 'Data Analyst' 'Data Scientist'\n",
      " 'Data Scientist' 'Data Scientist' 'Data Engineer' 'Data Engineer'\n",
      " 'Data Scientist' 'Data Analyst' 'Data Scientist' 'Data Scientist'\n",
      " 'Data Scientist' 'Data Analyst' 'Data Scientist' 'Data Analyst'\n",
      " 'Data Analyst' 'Data Scientist' 'Data Engineer' 'Data Scientist'\n",
      " 'Data Engineer' 'Data Scientist' 'Data Scientist' 'Data Analyst'\n",
      " 'Data Analyst' 'Data Scientist' 'Data Engineer' 'Data Scientist'\n",
      " 'Data Analyst' 'Data Scientist' 'Data Engineer' 'Data Analyst'\n",
      " 'Data Analyst' 'Data Engineer' 'Data Scientist' 'Data Engineer'\n",
      " 'Data Analyst' 'Data Scientist' 'Data Scientist' 'Data Engineer'\n",
      " 'Data Scientist' 'Data Scientist' 'Data Engineer' 'Data Scientist'\n",
      " 'Data Scientist' 'Data Analyst' 'Data Analyst' 'Data Analyst'\n",
      " 'Data Scientist' 'Data Analyst' 'Data Scientist' 'Data Analyst'\n",
      " 'Data Analyst' 'Data Engineer' 'Data Analyst' 'Data Scientist'\n",
      " 'Data Engineer' 'Data Scientist' 'Data Engineer' 'Data Scientist'\n",
      " 'Data Analyst' 'Data Engineer' 'Data Scientist' 'Data Scientist'\n",
      " 'Data Scientist' 'Data Engineer' 'Data Scientist' 'Data Analyst'\n",
      " 'Data Scientist' 'Data Analyst' 'Data Scientist' 'Data Engineer'\n",
      " 'Data Engineer' 'Data Engineer' 'Data Scientist' 'Data Scientist'\n",
      " 'Data Analyst' 'Data Analyst' 'Data Engineer' 'Data Engineer'\n",
      " 'Data Scientist' 'Data Analyst' 'Data Engineer' 'Data Engineer'\n",
      " 'Data Analyst' 'Data Analyst' 'Data Scientist' 'Data Scientist'\n",
      " 'Data Analyst' 'Data Engineer' 'Data Engineer' 'Data Scientist'\n",
      " 'Data Scientist' 'Data Engineer' 'Data Analyst' 'Data Analyst'\n",
      " 'Data Engineer' 'Data Scientist' 'Data Engineer' 'Data Analyst'\n",
      " 'Data Engineer' 'Data Scientist' 'Data Engineer' 'Data Analyst'\n",
      " 'Data Engineer' 'Data Engineer' 'Data Scientist' 'Data Scientist'\n",
      " 'Data Scientist' 'Data Scientist' 'Data Engineer' 'Data Scientist'\n",
      " 'Data Scientist' 'Data Analyst' 'Data Scientist' 'Data Scientist'\n",
      " 'Data Analyst' 'Data Engineer' 'Data Analyst' 'Data Analyst'\n",
      " 'Data Engineer' 'Data Engineer' 'Data Scientist' 'Data Scientist'\n",
      " 'Data Engineer' 'Data Engineer' 'Data Scientist' 'Data Analyst'\n",
      " 'Data Analyst' 'Data Engineer' 'Data Scientist' 'Data Scientist'\n",
      " 'Data Scientist' 'Data Scientist' 'Data Engineer' 'Data Analyst'\n",
      " 'Data Scientist' 'Data Analyst' 'Data Scientist' 'Data Analyst'\n",
      " 'Data Scientist' 'Data Scientist' 'Data Scientist' 'Data Engineer'\n",
      " 'Data Scientist' 'Data Analyst' 'Data Engineer' 'Data Analyst'\n",
      " 'Data Scientist' 'Data Analyst' 'Data Engineer' 'Data Scientist'\n",
      " 'Data Engineer' 'Data Engineer' 'Data Analyst' 'Data Scientist'\n",
      " 'Data Analyst' 'Data Engineer' 'Data Analyst' 'Data Engineer'\n",
      " 'Data Scientist' 'Data Scientist' 'Data Analyst' 'Data Analyst'\n",
      " 'Data Analyst' 'Data Analyst' 'Data Scientist' 'Data Scientist'\n",
      " 'Data Scientist' 'Data Scientist' 'Data Engineer' 'Data Scientist'\n",
      " 'Data Engineer' 'Data Scientist' 'Data Scientist' 'Data Analyst'\n",
      " 'Data Scientist' 'Data Scientist' 'Data Scientist' 'Data Scientist'\n",
      " 'Data Analyst' 'Data Analyst' 'Data Scientist' 'Data Analyst'\n",
      " 'Data Scientist' 'Data Analyst' 'Data Scientist' 'Data Scientist'\n",
      " 'Data Analyst' 'Data Scientist' 'Data Scientist' 'Data Scientist'\n",
      " 'Data Scientist' 'Data Scientist' 'Data Analyst' 'Data Scientist'\n",
      " 'Data Engineer' 'Data Analyst' 'Data Engineer' 'Data Analyst'\n",
      " 'Data Analyst' 'Data Scientist' 'Data Engineer' 'Data Engineer'\n",
      " 'Data Engineer' 'Data Scientist' 'Data Analyst' 'Data Scientist'\n",
      " 'Data Scientist' 'Data Analyst' 'Data Scientist' 'Data Engineer'\n",
      " 'Data Scientist' 'Data Analyst' 'Data Scientist' 'Data Engineer'\n",
      " 'Data Engineer' 'Data Engineer' 'Data Scientist' 'Data Engineer'\n",
      " 'Data Engineer' 'Data Analyst' 'Data Analyst' 'Data Scientist'\n",
      " 'Data Scientist' 'Data Scientist' 'Data Scientist' 'Data Analyst'\n",
      " 'Data Scientist' 'Data Scientist' 'Data Analyst' 'Data Scientist'\n",
      " 'Data Scientist' 'Data Scientist' 'Data Analyst' 'Data Engineer'\n",
      " 'Data Analyst' 'Data Analyst' 'Data Analyst' 'Data Analyst'\n",
      " 'Data Analyst' 'Data Scientist' 'Data Analyst' 'Data Scientist'\n",
      " 'Data Analyst' 'Data Engineer' 'Data Analyst' 'Data Engineer'\n",
      " 'Data Engineer' 'Data Analyst' 'Data Scientist' 'Data Analyst'\n",
      " 'Data Scientist' 'Data Scientist' 'Data Engineer' 'Data Scientist'\n",
      " 'Data Scientist' 'Data Analyst' 'Data Analyst' 'Data Engineer'\n",
      " 'Data Analyst' 'Data Scientist' 'Data Scientist' 'Data Engineer'\n",
      " 'Data Scientist' 'Data Scientist' 'Data Engineer' 'Data Scientist'\n",
      " 'Data Analyst' 'Data Analyst' 'Data Scientist' 'Data Engineer'\n",
      " 'Data Analyst' 'Data Scientist' 'Data Engineer' 'Data Analyst'\n",
      " 'Data Analyst' 'Data Scientist' 'Data Analyst' 'Data Engineer'\n",
      " 'Data Analyst' 'Data Scientist' 'Data Analyst' 'Data Scientist'\n",
      " 'Data Scientist' 'Data Analyst' 'Data Analyst' 'Data Engineer'\n",
      " 'Data Engineer' 'Data Analyst' 'Data Analyst' 'Data Scientist'\n",
      " 'Data Analyst' 'Data Scientist' 'Data Analyst' 'Data Analyst'\n",
      " 'Data Analyst' 'Data Engineer' 'Data Analyst' 'Data Scientist'\n",
      " 'Data Scientist' 'Data Analyst' 'Data Analyst' 'Data Engineer'\n",
      " 'Data Engineer' 'Data Engineer' 'Data Scientist' 'Data Scientist'\n",
      " 'Data Scientist' 'Data Analyst' 'Data Engineer' 'Data Engineer'\n",
      " 'Data Analyst' 'Data Scientist' 'Data Analyst' 'Data Engineer'\n",
      " 'Data Engineer' 'Data Analyst' 'Data Scientist' 'Data Analyst'\n",
      " 'Data Analyst' 'Data Scientist' 'Data Analyst' 'Data Scientist'\n",
      " 'Data Scientist' 'Data Analyst' 'Data Scientist' 'Data Analyst'\n",
      " 'Data Scientist' 'Data Scientist' 'Data Engineer' 'Data Scientist'\n",
      " 'Data Engineer' 'Data Engineer' 'Data Analyst' 'Data Analyst'\n",
      " 'Data Scientist' 'Data Analyst' 'Data Analyst' 'Data Scientist']\n"
     ]
    }
   ],
   "source": [
    "#print the prediction\n",
    "print(classifier.predict(X_train))\n",
    "#print values\n",
    "print(y_train.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                precision    recall  f1-score   support\n",
      "\n",
      "  Data Analyst       0.95      0.90      0.92       149\n",
      " Data Engineer       0.94      0.98      0.96       112\n",
      "Data Scientist       0.93      0.94      0.94       195\n",
      "\n",
      "      accuracy                           0.94       456\n",
      "     macro avg       0.94      0.94      0.94       456\n",
      "  weighted avg       0.94      0.94      0.94       456\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Evaluate the model on the training data set \n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "prediction = classifier.predict(X_train)\n",
    "print(classification_report(y_train, prediction))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix: \n",
      " [[134   2  13]\n",
      " [  1 110   1]\n",
      " [  6   5 184]]\n",
      "Accuracy Matrix: 0.9385964912280702\n"
     ]
    }
   ],
   "source": [
    "print('Confusion Matrix: \\n', confusion_matrix(y_train,prediction))\n",
    "print('Accuracy Matrix:',  accuracy_score(y_train,prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Data Analyst' 'Data Scientist' 'Data Scientist' 'Data Engineer'\n",
      " 'Data Analyst' 'Data Engineer' 'Data Engineer' 'Data Analyst'\n",
      " 'Data Analyst' 'Data Engineer' 'Data Scientist' 'Data Scientist'\n",
      " 'Data Engineer' 'Data Scientist' 'Data Scientist' 'Data Analyst'\n",
      " 'Data Engineer' 'Data Scientist' 'Data Engineer' 'Data Scientist'\n",
      " 'Data Engineer' 'Data Scientist' 'Data Analyst' 'Data Scientist'\n",
      " 'Data Scientist' 'Data Analyst' 'Data Engineer' 'Data Scientist'\n",
      " 'Data Scientist' 'Data Scientist' 'Data Scientist' 'Data Engineer'\n",
      " 'Data Analyst' 'Data Scientist' 'Data Analyst' 'Data Analyst'\n",
      " 'Data Scientist' 'Data Analyst' 'Data Scientist' 'Data Analyst'\n",
      " 'Data Scientist' 'Data Analyst' 'Data Scientist' 'Data Scientist'\n",
      " 'Data Analyst' 'Data Scientist' 'Data Scientist' 'Data Scientist'\n",
      " 'Data Analyst' 'Data Scientist' 'Data Analyst' 'Data Analyst'\n",
      " 'Data Engineer' 'Data Scientist' 'Data Analyst' 'Data Analyst'\n",
      " 'Data Scientist' 'Data Scientist' 'Data Engineer' 'Data Scientist'\n",
      " 'Data Analyst' 'Data Scientist' 'Data Scientist' 'Data Engineer'\n",
      " 'Data Analyst' 'Data Engineer' 'Data Engineer' 'Data Scientist'\n",
      " 'Data Analyst' 'Data Scientist' 'Data Scientist' 'Data Scientist'\n",
      " 'Data Scientist' 'Data Analyst' 'Data Analyst' 'Data Scientist'\n",
      " 'Data Scientist' 'Data Scientist' 'Data Analyst' 'Data Analyst'\n",
      " 'Data Engineer' 'Data Scientist' 'Data Engineer' 'Data Engineer'\n",
      " 'Data Analyst' 'Data Analyst' 'Data Analyst' 'Data Scientist'\n",
      " 'Data Analyst' 'Data Scientist' 'Data Scientist' 'Data Analyst'\n",
      " 'Data Scientist' 'Data Analyst' 'Data Scientist' 'Data Engineer'\n",
      " 'Data Analyst' 'Data Scientist' 'Data Scientist' 'Data Engineer'\n",
      " 'Data Scientist' 'Data Engineer' 'Data Engineer' 'Data Analyst'\n",
      " 'Data Scientist' 'Data Scientist' 'Data Scientist' 'Data Scientist'\n",
      " 'Data Scientist' 'Data Scientist' 'Data Analyst' 'Data Scientist'\n",
      " 'Data Analyst' 'Data Analyst']\n",
      "['Data Analyst' 'Data Scientist' 'Data Scientist' 'Data Engineer'\n",
      " 'Data Analyst' 'Data Engineer' 'Data Engineer' 'Data Analyst'\n",
      " 'Data Analyst' 'Data Engineer' 'Data Scientist' 'Data Scientist'\n",
      " 'Data Scientist' 'Data Analyst' 'Data Scientist' 'Data Analyst'\n",
      " 'Data Engineer' 'Data Scientist' 'Data Engineer' 'Data Scientist'\n",
      " 'Data Engineer' 'Data Engineer' 'Data Analyst' 'Data Scientist'\n",
      " 'Data Analyst' 'Data Engineer' 'Data Engineer' 'Data Analyst'\n",
      " 'Data Scientist' 'Data Scientist' 'Data Scientist' 'Data Engineer'\n",
      " 'Data Analyst' 'Data Engineer' 'Data Engineer' 'Data Engineer'\n",
      " 'Data Scientist' 'Data Scientist' 'Data Scientist' 'Data Analyst'\n",
      " 'Data Scientist' 'Data Analyst' 'Data Scientist' 'Data Scientist'\n",
      " 'Data Analyst' 'Data Scientist' 'Data Scientist' 'Data Scientist'\n",
      " 'Data Analyst' 'Data Engineer' 'Data Analyst' 'Data Engineer'\n",
      " 'Data Engineer' 'Data Scientist' 'Data Analyst' 'Data Analyst'\n",
      " 'Data Scientist' 'Data Scientist' 'Data Engineer' 'Data Analyst'\n",
      " 'Data Analyst' 'Data Scientist' 'Data Scientist' 'Data Engineer'\n",
      " 'Data Analyst' 'Data Engineer' 'Data Engineer' 'Data Scientist'\n",
      " 'Data Analyst' 'Data Scientist' 'Data Scientist' 'Data Scientist'\n",
      " 'Data Scientist' 'Data Analyst' 'Data Analyst' 'Data Scientist'\n",
      " 'Data Scientist' 'Data Scientist' 'Data Analyst' 'Data Engineer'\n",
      " 'Data Engineer' 'Data Scientist' 'Data Analyst' 'Data Engineer'\n",
      " 'Data Analyst' 'Data Analyst' 'Data Analyst' 'Data Analyst'\n",
      " 'Data Scientist' 'Data Scientist' 'Data Scientist' 'Data Analyst'\n",
      " 'Data Scientist' 'Data Engineer' 'Data Scientist' 'Data Engineer'\n",
      " 'Data Analyst' 'Data Scientist' 'Data Scientist' 'Data Engineer'\n",
      " 'Data Scientist' 'Data Engineer' 'Data Scientist' 'Data Engineer'\n",
      " 'Data Scientist' 'Data Analyst' 'Data Scientist' 'Data Analyst'\n",
      " 'Data Scientist' 'Data Scientist' 'Data Analyst' 'Data Analyst'\n",
      " 'Data Scientist' 'Data Analyst']\n"
     ]
    }
   ],
   "source": [
    "#print the prediction\n",
    "print(classifier.predict(X_test))\n",
    "#print values\n",
    "print(y_test.values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                precision    recall  f1-score   support\n",
      "\n",
      "  Data Analyst       0.73      0.75      0.74        36\n",
      " Data Engineer       0.86      0.66      0.75        29\n",
      "Data Scientist       0.80      0.90      0.85        49\n",
      "\n",
      "      accuracy                           0.79       114\n",
      "     macro avg       0.80      0.77      0.78       114\n",
      "  weighted avg       0.79      0.79      0.79       114\n",
      "\n",
      "\n",
      "Confusion Matrix: \n",
      " [[27  1  8]\n",
      " [ 7 19  3]\n",
      " [ 3  2 44]]\n",
      "\n",
      "Accuracy Matrix: 0.7894736842105263\n"
     ]
    }
   ],
   "source": [
    "#Evaluate the model on the training data set \n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "prediction = classifier.predict(X_test)\n",
    "print(classification_report(y_test, prediction))\n",
    "print()\n",
    "print('Confusion Matrix: \\n', confusion_matrix(y_test,prediction))\n",
    "print()\n",
    "print('Accuracy Matrix:',  accuracy_score(y_test,prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 14)\t1\n",
      "  (0, 157)\t1\n",
      "  (0, 266)\t1\n",
      "  (0, 509)\t1\n",
      "  (0, 627)\t1\n",
      "  (0, 657)\t1\n",
      "  (0, 714)\t3\n",
      "  (0, 760)\t1\n",
      "  (0, 1115)\t1\n",
      "  (0, 1156)\t1\n",
      "  (0, 1266)\t1\n",
      "  (0, 1367)\t1\n",
      "  (0, 1373)\t3\n",
      "  (0, 1420)\t1\n",
      "  (0, 1437)\t1\n",
      "  (0, 1439)\t1\n",
      "  (0, 1458)\t2\n",
      "  (0, 1463)\t1\n",
      "  (0, 1481)\t1\n",
      "  (0, 1486)\t1\n",
      "  (0, 1541)\t1\n",
      "  (0, 1721)\t2\n",
      "  (0, 1831)\t1\n",
      "  (0, 1909)\t2\n",
      "  (0, 2252)\t2\n",
      "  :\t:\n",
      "  (0, 11584)\t3\n",
      "  (0, 11613)\t1\n",
      "  (0, 11672)\t1\n",
      "  (0, 11684)\t2\n",
      "  (0, 11721)\t1\n",
      "  (0, 11725)\t1\n",
      "  (0, 11778)\t3\n",
      "  (0, 11794)\t3\n",
      "  (0, 11801)\t3\n",
      "  (0, 11805)\t1\n",
      "  (0, 11811)\t1\n",
      "  (0, 11813)\t1\n",
      "  (0, 11857)\t1\n",
      "  (0, 11861)\t2\n",
      "  (0, 11862)\t1\n",
      "  (0, 11967)\t2\n",
      "  (0, 12236)\t3\n",
      "  (0, 12243)\t1\n",
      "  (0, 12276)\t1\n",
      "  (0, 12398)\t1\n",
      "  (0, 12420)\t1\n",
      "  (0, 12440)\t1\n",
      "  (0, 12494)\t1\n",
      "  (0, 12509)\t1\n",
      "  (0, 12512)\t1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['Data Scientist'], dtype='<U14')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example = ['Weldon Schmidt \\\n",
    "59222 Yundt Falls, Philadelphia, PA \\\n",
    "+1 (555) 408 5416 Work Experience \\\n",
    "07/2017 - PRESENT \\\n",
    "Lead Big Data Engineer \\\n",
    "Boston, MA \\\n",
    "Support, maintain, and document Hadoop and MySQL data warehouse \\\n",
    "Iterate and improve existing features in the pipeline as well as add new ones \\\n",
    "Design, develop, document, and test new requirements in the data pipeline using PERL, BASH, PIG and OOZIE in the Hadoop ecosystem \\\n",
    "Provide full operational support – analyze code to identify root causes of production issues and provide solutions or workarounds and lead it to resolution \\\n",
    "Participate in full development life cycle including requirements analysis, design, development, deployment and operations support \\\n",
    "Work with engineering team members to explore and create interesting solutions while sharing knowledge within the team \\\n",
    "Work across product teams to help solve customer-facing issues \\\n",
    "Demonstrable experience designing technological solutions to complex data problems, developing & testing modular, reusable, efficient and scalable code to implement those solutions \\\n",
    "Big Data Engineer\\\n",
    "10/2011 - 03/2017 \\\n",
    "Dallas, TX \\\n",
    "Plan, develop, monitor and evolve needed infrastructure in collaboration with Ops partners \\\n",
    "Progressive experience as a Systems/Software Engineer, Application Developer or related occupation \\\n",
    "Provides technical design based on business requirements \\\n",
    "Communicates and coordinates with cross functional teams to ensure business objectives are met \\\n",
    "Develops, tests and deploys software applications/systems using scientific analysis and mathematical models to predict and measure outcome and consequences of design \\\n",
    "Provides guidance and mentoring in technical areas to a team of Developer/Analysts \\\n",
    "Documents and submits status reports to leadership \\\n",
    "Provides guidance on new technologies/methodologies \\\n",
    "Junior Big Data Engineer\\\n",
    "09/2004 - 09/2011 \\\n",
    "Detroit, MI \\\n",
    "Designing, developing and maintaining new generation machine learning based big-data web page categorization, data/IP mining, and malicious site detection systems \\\n",
    "Creating and enhancing tools to analyze and process large quantity of data set \\\n",
    "Utilize your programming skills for efficient and robust implementation \\\n",
    "Work closely with malware research/data science teams to enhance malicious site detection, and machine learning/data mining based big data system \\\n",
    "Solve engineering problems by creating solutions that leverage existing technologies and utilize your technical prowess to design and implement solutions where none exist \\\n",
    "Design, build, improve and maintain a high performance and highly scalable services exposed to our solution and a broader development community \\\n",
    "Work with real-time data processing, messaging, streaming techniques and workflows \\\n",
    "University of Sioux Falls \\\n",
    "1998 - 2003 \\\n",
    "Bachelors Degree in Computer Science \\\n",
    "Professional Skills \\\n",
    "Very strong skills working with very large data sets with a variety of tools; experience in dealing with performance and scaling issues \\\n",
    "Demonstrated excellent planning and organizational skills \\\n",
    "Proven design, coding, testing and debugging skills and experience \\\n",
    "Strong analytical, learning and problem solving skills with personal interest in subjects such as math/statistics, machine learning, AI and analytics \\\n",
    "Self-starting, requiring minimal supervision with strong problem-solving skills \\\n",
    "Relevant software development / consulting experience with strong skill on database modeling and architecture \\\n",
    "Strong execution skills in a fast-paced environment using agile methodologies']\n",
    "input_bow = count_v.transform(example)\n",
    "print(input_bow)\n",
    "# classifier =  MultinomialNB().fit(X1_train, y1_train)\n",
    "classifier.predict(input_bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nbconvert in /Users/williammdavis/opt/anaconda3/lib/python3.7/site-packages (5.6.1)\n",
      "Requirement already satisfied: entrypoints>=0.2.2 in /Users/williammdavis/opt/anaconda3/lib/python3.7/site-packages (from nbconvert) (0.3)\n",
      "Requirement already satisfied: jupyter-core in /Users/williammdavis/opt/anaconda3/lib/python3.7/site-packages (from nbconvert) (4.6.1)\n",
      "Requirement already satisfied: traitlets>=4.2 in /Users/williammdavis/opt/anaconda3/lib/python3.7/site-packages (from nbconvert) (4.3.3)\n",
      "Requirement already satisfied: pygments in /Users/williammdavis/opt/anaconda3/lib/python3.7/site-packages (from nbconvert) (2.5.2)\n",
      "Requirement already satisfied: bleach in /Users/williammdavis/opt/anaconda3/lib/python3.7/site-packages (from nbconvert) (3.1.0)\n",
      "Requirement already satisfied: defusedxml in /Users/williammdavis/opt/anaconda3/lib/python3.7/site-packages (from nbconvert) (0.6.0)\n",
      "Requirement already satisfied: mistune<2,>=0.8.1 in /Users/williammdavis/opt/anaconda3/lib/python3.7/site-packages (from nbconvert) (0.8.4)\n",
      "Requirement already satisfied: jinja2>=2.4 in /Users/williammdavis/opt/anaconda3/lib/python3.7/site-packages (from nbconvert) (2.11.1)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in /Users/williammdavis/opt/anaconda3/lib/python3.7/site-packages (from nbconvert) (1.4.2)\n",
      "Requirement already satisfied: testpath in /Users/williammdavis/opt/anaconda3/lib/python3.7/site-packages (from nbconvert) (0.4.4)\n",
      "Requirement already satisfied: nbformat>=4.4 in /Users/williammdavis/opt/anaconda3/lib/python3.7/site-packages (from nbconvert) (5.0.4)\n",
      "Requirement already satisfied: decorator in /Users/williammdavis/opt/anaconda3/lib/python3.7/site-packages (from traitlets>=4.2->nbconvert) (4.4.1)\n",
      "Requirement already satisfied: six in /Users/williammdavis/opt/anaconda3/lib/python3.7/site-packages (from traitlets>=4.2->nbconvert) (1.14.0)\n",
      "Requirement already satisfied: ipython-genutils in /Users/williammdavis/opt/anaconda3/lib/python3.7/site-packages (from traitlets>=4.2->nbconvert) (0.2.0)\n",
      "Requirement already satisfied: webencodings in /Users/williammdavis/opt/anaconda3/lib/python3.7/site-packages (from bleach->nbconvert) (0.5.1)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /Users/williammdavis/opt/anaconda3/lib/python3.7/site-packages (from jinja2>=2.4->nbconvert) (1.1.1)\n",
      "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /Users/williammdavis/opt/anaconda3/lib/python3.7/site-packages (from nbformat>=4.4->nbconvert) (3.2.0)\n",
      "Requirement already satisfied: attrs>=17.4.0 in /Users/williammdavis/opt/anaconda3/lib/python3.7/site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.4->nbconvert) (19.3.0)\n",
      "Requirement already satisfied: setuptools in /Users/williammdavis/opt/anaconda3/lib/python3.7/site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.4->nbconvert) (46.0.0.post20200309)\n",
      "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /Users/williammdavis/opt/anaconda3/lib/python3.7/site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.4->nbconvert) (1.5.0)\n",
      "Requirement already satisfied: pyrsistent>=0.14.0 in /Users/williammdavis/opt/anaconda3/lib/python3.7/site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.4->nbconvert) (0.15.7)\n",
      "Requirement already satisfied: zipp>=0.5 in /Users/williammdavis/opt/anaconda3/lib/python3.7/site-packages (from importlib-metadata; python_version < \"3.8\"->jsonschema!=2.5.0,>=2.4->nbformat>=4.4->nbconvert) (2.2.0)\n",
      "\u001b[33mWARNING: You are using pip version 20.2.4; however, version 20.3.1 is available.\n",
      "You should consider upgrading via the '/Users/williammdavis/opt/anaconda3/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "[NbConvertApp] Converting notebook Project_3.ipynb to python\n",
      "[NbConvertApp] Writing 6825 bytes to Project_3.py\n"
     ]
    }
   ],
   "source": [
    "!pip install nbconvert\n",
    "!jupyter nbconvert --to python Project_3.ipynb\n",
    "# !mv mission_to_mars.py scrape_mars.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'encoding' is an invalid keyword argument for dump()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-e541ac197a42>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# class NaiveBayesClpickl = {'model': count_v}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mpickl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0;34m'model_file'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\".p\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"wb\"\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'unicode_escape'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: 'encoding' is an invalid keyword argument for dump()"
     ]
    }
   ],
   "source": [
    "# class NaiveBayesClpickl = {'model': count_v}\n",
    "pickle.dump( pickl, open( 'model_file' + \".p\", \"wb\", encoding = 'unicode_escape'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
